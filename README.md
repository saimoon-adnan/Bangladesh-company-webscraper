Web Scraping Bangladesh Company Data (Wikipedia Table Scraper)

This project extracts company information from the Wikipedia page
â€œList of companies of Bangladeshâ€ and converts all tables into clean and structured CSV files.
It demonstrates skills in web scraping, data cleaning, pandas, and BeautifulSoup.

 --Project Overview--

This project scrapes:

âœ” All tables from Wikipedia 
âœ” Extracts table headers & rows
âœ” Cleans the data 
âœ” Saves each table into separate CSV files 
âœ” Displays DataFrames inside Jupyter Notebook

Itâ€™s perfect for learning and showcasing web scraping skills.

 --Technologies Used--
Python 3
BeautifulSoup (bs4)
Requests
Pandas
Jupyter Notebook

--Project Structure--
ğŸ“ Bangladesh-Web-Scraper/
â”‚â”€â”€ scraper.ipynb
â”‚â”€â”€ data/
â”‚    â”œâ”€â”€ table_1.csv
â”‚    â”œâ”€â”€ table_2.csv
â”‚    â”œâ”€â”€ ...
â”‚â”€â”€ README.md
â”‚â”€â”€ requirements.txt



--How It Works--
Send an HTTP request to Wikipedia
Parse HTML using BeautifulSoup
Locate all <table class="wikitable">
Extract header + row data
Convert to Pandas DataFrame
Save DataFrames into CSV files

--Purpose of This Project--
This project is ideal for:
Learning web scraping
Portfolio preparation
Data analysis practice
GitHub demonstration
Understanding HTML parsing

--Run the code--
pip install -r requirements.txt
jupyter notebook

--Author--
Saimoon Adnan









